{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Project I: </b>Lyft Bikes (BayWheels) Promotion Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Introduction</b>\n",
    "\n",
    "Founded in August 29, 2013, Lyft's Bay Wheels (formerly Ford GoBike) entered the Bay Area bike share market to compete directly with Uber's JUMP bike share service (founded roughly three years prior in 2010). As a direct competitor to the incumbent, Uber's JUMP, Lyft's own <i>Bay Wheels</i> has a strong incentive to increase ridership and to grow their market share in the bike share service marketplace. To achieve this goals, I conducted an analysis on prior Lyft Bike data (from BayWheel's founding on August 29, 2013 through August 31, 2016, to get a better understanding of the ridership and identify areas of opportunity for growth. \n",
    "\n",
    "For this analysis we want to address 2 main questions:\n",
    "\n",
    "<b>1. What are the 5 most popular trips that we would call \"commuter trips\"? </b> \n",
    "\n",
    "<b>2. What recommendations should Lyft Bikes take to increase their ridership? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Summary </b>\n",
    "### Top 5 Most Popular \"Commuter\" Trips\n",
    "\n",
    "Answering the first of the 2 main questions is imperative to understanding Lyft's Bike ridership. According to the [US Census Bureau report](https://www.census.gov/newsroom/press-releases/2014/cb14-86.html) published on May 08, 2014, there has been a 60% increase in biking to work over the last decade. By understanding the most popular \"commuter\" trips, I can understand Lyft's current state better.\n",
    "\n",
    "I defined a commuter trip as a trip satisfying all of the following requirements:  \n",
    "\n",
    "1. a trip between the hours of 7 AM - 9 AM and 4PM - 6PM during the weekdays (Monday - Friday).  \n",
    "    - This was determined according to a [trip advisor forum post](https://www.tripadvisor.com/ShowTopic-g60713-i30-k2240412-Rush_hour_in_SF-San_Francisco_California.html#:~:text=Typical%20rush%20hour%20times%20are,SFO%20on%20a%20Saturday%2C%20though.) denoting such times as rush hour in the Bay Area  \n",
    "\n",
    "2. a trip not lasting a minimum of 2 minutes and not in excess of 60 minutes\n",
    "    - This was determined according to a post by [mobilitylab.org](https://mobilitylab.org/2017/02/27/how-far-bike-work/) that stated a bike commute to work should be not in excess of 10 miles, roughly a 60 minute bike commute.  \n",
    "\n",
    "3. Having a differing start and end bike station, assuming commuters are traveling in one direction as versus a round trip \n",
    "\n",
    "\n",
    "<b>The Top 5 Most Popular \"Commuter\" Trips are the trips in the below table:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: bq: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! bq query --use_legacy_sql=FALSE --format=csv 'SELECT start_station_name, end_station_name, count(*) as commuter_trips FROM `bike_trip_data.trips_full_commute_pst` WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec < 3600 AND duration_sec > 120 AND Commute = \"Yes\" GROUP BY start_station_name, end_station_name ORDER BY commuter_trips DESC LIMIT 5' > top_5_commuter_trips.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0efac7053d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top_5_commuter_trips.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "top_5 = pd.read_csv('top_5_commuter_trips.csv')\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Final Recommendation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upon conclusion of my analysis, I recommend Lyft offer the following promotion cycle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Lyft Bikes should increase and add promotions to offer monthly subscriptions to current customers who take Lyft bikes on the weekends. Additionally, Lyft should advertise the top 5 most popular non-commuter rides that subscribers have taken from the customer's geographic landmark. </b> \n",
    "- New bike trip recommendations would provides 5 new bike trips that they can try, allowing individuals who enjoyed their Lyft Bike experience to feel more compelled to purchase a subscription and complete these suggested trips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To justify the recommendations above, I began by taking a looking at the current distribution of riders in the dataset. I wanted to see when Lyft Bikes were the most busy and where Lyft Bikes were the least busy to understand where there is the most opportunity for growth and if there are any constraints that may prevent certain promotions from being effective. \n",
    "\n",
    "<i>I defined the event of being busy as the event that at any given status check there is a low availability of bikes, where less that 25% of bikes are available for rental at any given station.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Plotting Busy Lyft Bikes' Days</b>\n",
    "\n",
    "### Overall Business (Subscribers and Customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT status_check_day_of_week AS day_of_week, COUNT(status_check_date) AS no_of_low_availability FROM `bike_trip_data.status_w_availability` WHERE bike_availability = \"low\" GROUP BY status_check_day_of_week ORDER BY no_of_low_availability' > ride_freq_dow.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_dow = pd.read_csv('ride_freq_dow.csv')\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.bar(availability_dow.day_of_week, availability_dow.no_of_low_availability, color = 'm')\n",
    "plt.ylim(0,np.max(availability_dow.no_of_low_availability)+40000)\n",
    "plt.yticks(np.arange(0, np.max(availability_dow.no_of_low_availability)+40000, 500000))\n",
    "plt.ylabel('Number of Busy Status Checks (in Millions)')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.title('Lyft Bike: Number of Busy Events Per Day of the Week (Overall Users)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Analysis: </b> While this is really helpful, we need to dig even deeper to understand when customers are taking bike rides to understand when it is most effective to target them for promotions and advertising. I decided to look at Customer Bike Ride Frequencies next in order to see when there were the most customers riding bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Customer Bike Ride Frequency </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_day_of_week, COUNT(distinct pst_trip_id) AS number_of_trips FROM `bike_trip_data.trips_full_commute_pst`  WHERE subscriber_type = \"Customer\" GROUP BY start_day_of_week ORDER BY number_of_trips DESC' > sub_trips.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_trips = pd.read_csv('sub_trips.csv')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(sub_trips.start_day_of_week, sub_trips.number_of_trips, color = 'm')\n",
    "plt.ylabel('Number of Customer Bike Rides')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.title('Lyft Bike Growth Opportunity: Customer Bike Ride Frequencies By Day of Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the graph, there are significantly less status checks with less than 25% of bikes available to ride on the weekend (Saturday & Sunday). There were also a  relatively high frequency of status checks that had low bike availability during the weekdays. Therefore I don't see having promotions catered towards customers during the weekday as an effective promotion campaign because the weekdays have more low availability events which means that there would be less opportunity for subscribers to get a bike rental during the week than during the weekend. <b>Therefore, I recommend having promotional campaigns for users to sign up for a monthly subscription of Lyft Bikes during the weekend.</b> Having a promotion during the weekend allows for:\n",
    "- a higher likelihood that new subscribers will have a positive experience with Lyft Bikes because of increased bike availability and therefore, increased bike selection options\n",
    "- Greater opportunity to grow ridership because of more bike trips by Customers during the weekend\n",
    "    - <u><i>Figure 2</i></u> shows the highest volume of Customer Bike Rides on the weekends. Promotions targeting Customers will be most effective here as Customers are the most active renting Lyft Bikes during the weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Recommendations to Incentivize Potential Subscribers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>By providing 5 new trip ideas that a potential subscriber may be interested in based on their geographic location, Lyft can customize their user's experience and incentivize additional trips through a subscription.</b> To provide the most accurate recommendation of the next 5 potential trips, I subset the data to only include subscribers that took trips on the weekends in the landmark areas near the customer's end station. This filters out commuter trips that maybe irrelevant to the potential subscriber and trips that would require additional travel farther from a customer's current location. This would subset the trip routes to only those that are more likely to be nearby leisure trips than work commutes; increasing the likelihood that a trip will be enjoyable for the weekend customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of theses trips are between 15 - 30 minutes one way, allowing customers to feel incentivized to purchase a monthly subscription because of the short trip duration and the popularity of these short getaways with Lyft Bike subscribers. This may incentivize some to purchase monthly subscriptions as a way to \"get in on the fun\" that Lyft Bike subscribers have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Trips in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redwood City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_station_name, end_station_name, COUNT(*) AS subscriber_trips FROM `bike_trip_data.end_trip_landmarks`  WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec <= 1800 AND duration_sec >= 900 AND landmark = \"Redwood City\" GROUP BY start_station_name, end_station_name ORDER BY subscriber_trips DESC LIMIT 5' > redwood_city_top_5.csv\n",
    "rwc = pd.read_csv('redwood_city_top_5.csv')\n",
    "rwc.columns = ['Start Station', 'End Station', 'Number of Subscribers Trip']\n",
    "rwc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### San Jose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_station_name, end_station_name, COUNT(*) AS subscriber_trips FROM `bike_trip_data.end_trip_landmarks`  WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec <= 1800 AND duration_sec >= 900 AND landmark = \"San Jose\" GROUP BY start_station_name, end_station_name ORDER BY subscriber_trips DESC LIMIT 5' > san_jose_top_5.csv\n",
    "sj = pd.read_csv('san_jose_top_5.csv')\n",
    "sj.columns = ['Start Station', 'End Station', 'Number of Subscribers Trip']\n",
    "sj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_station_name, end_station_name, COUNT(*) AS subscriber_trips FROM `bike_trip_data.end_trip_landmarks`  WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec <= 1800 AND duration_sec >= 900 AND landmark = \"San Francisco\" GROUP BY start_station_name, end_station_name ORDER BY subscriber_trips DESC LIMIT 5' > san_francisco_top_5.csv\n",
    "sf = pd.read_csv('san_francisco_top_5.csv')\n",
    "sf.columns = ['Start Station', 'End Station', 'Number of Subscribers Trip']\n",
    "sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palo Alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_station_name, end_station_name, COUNT(*) AS subscriber_trips FROM `bike_trip_data.end_trip_landmarks`  WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec <= 1800 AND duration_sec >= 900 AND landmark = \"Palo Alto\" GROUP BY start_station_name, end_station_name ORDER BY subscriber_trips DESC LIMIT 5' > palo_alto_top_5.csv\n",
    "pa = pd.read_csv('palo_alto_top_5.csv')\n",
    "pa.columns = ['Start Station', 'End Station', 'Number of Subscribers Trip']\n",
    "pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mountain View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bq query --use_legacy_sql=False --format=csv 'SELECT start_station_name, end_station_name, COUNT(*) AS subscriber_trips FROM `bike_trip_data.end_trip_landmarks`  WHERE start_date_pst = end_date_pst AND start_station_name <> end_station_name AND duration_sec <= 1800 AND duration_sec >= 900 AND landmark = \"Mountain View\" GROUP BY start_station_name, end_station_name ORDER BY subscriber_trips DESC LIMIT 5' > mountain_view_top_5.csv\n",
    "mv = pd.read_csv('mountain_view_top_5.csv')\n",
    "mv.columns = ['Start Station', 'End Station', 'Number of Subscribers Trip']\n",
    "mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Appendix</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Subquery Views Used in Google BigQuery:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `bike_trip_data.trips_full_commute_pst`\n",
    "\n",
    "``` sql\n",
    "SELECT\n",
    "  trip_id AS pst_trip_id,\n",
    "  DATE(start_date) AS start_date_pst,\n",
    "  TIME(start_date) AS start_time_pst,\n",
    "  CASE\n",
    "    WHEN EXTRACT(HOUR FROM TIME(start_date)) >= 4 AND EXTRACT(HOUR FROM TIME(start_date)) < 12 THEN 'Morning'\n",
    "    WHEN EXTRACT(HOUR FROM TIME(start_date)) >= 12 AND EXTRACT(HOUR FROM TIME(start_date)) < 18 THEN 'Afternoon'\n",
    "    WHEN EXTRACT(HOUR FROM TIME(start_date)) >= 18 AND EXTRACT(HOUR FROM TIME(start_date)) < 24 THEN 'Evening'\n",
    "    ELSE 'Midnight'\n",
    "    END AS start_time_of_day,\n",
    "  CASE EXTRACT (DAYOFWEEK FROM DATE(start_date))\n",
    "    WHEN 1 THEN 'Sunday'\n",
    "    WHEN 2 THEN 'Monday'\n",
    "    WHEN 3 THEN 'Tuesday'\n",
    "    WHEN 4 THEN 'Wednesday'\n",
    "    WHEN 5 THEN 'Thursday'\n",
    "    WHEN 6 THEN 'Friday'\n",
    "    WHEN 7 THEN 'Saturday'\n",
    "    END AS start_day_of_week,\n",
    "  CASE\n",
    "    WHEN EXTRACT(DAYOFWEEK FROM DATE(start_date)) NOT IN (1, 7) THEN 'Weekday'\n",
    "    ELSE 'Weekend'\n",
    "    END AS start_weekday,\n",
    "  DATE(end_date) AS end_date_pst,\n",
    "  TIME(end_date) AS end_time_pst,\n",
    "  CASE\n",
    "    WHEN EXTRACT(HOUR FROM TIME(end_date)) >= 4 AND EXTRACT(HOUR FROM TIME(end_date)) < 12 THEN 'Morning'\n",
    "    WHEN EXTRACT(HOUR FROM TIME(end_date)) >= 12 AND EXTRACT(HOUR FROM TIME(end_date)) < 18 THEN 'Afternoon'\n",
    "    WHEN EXTRACT(HOUR FROM TIME(end_date)) >= 18 AND EXTRACT(HOUR FROM TIME(end_date)) < 24 THEN 'Evening'\n",
    "    ELSE 'Midnight'\n",
    "    END AS end_time_of_day,\n",
    "  CASE EXTRACT (DAYOFWEEK FROM DATE(end_date))\n",
    "    WHEN 1 THEN 'Sunday'\n",
    "    WHEN 2 THEN 'Monday'\n",
    "    WHEN 3 THEN 'Tuesday'\n",
    "    WHEN 4 THEN 'Wednesday'\n",
    "    WHEN 5 THEN 'Thursday'\n",
    "    WHEN 6 THEN 'Friday'\n",
    "    WHEN 7 THEN 'Saturday'\n",
    "    END AS end_day_of_week,\n",
    "  CASE\n",
    "    WHEN EXTRACT(DAYOFWEEK FROM DATE(end_date)) NOT IN (1, 7) THEN 'Weekday'\n",
    "    ELSE 'Weekend'\n",
    "    END AS end_weekday,\n",
    "  CASE\n",
    "    WHEN EXTRACT (HOUR FROM TIME(start_date)) IN (7, 8, 9) THEN 'AM'\n",
    "    WHEN EXTRACT (HOUR FROM TIME(start_date)) IN (16, 17, 18) THEN 'PM'\n",
    "    ELSE 'Not Commute'\n",
    "    END AS ampm_commute,\n",
    "  CASE\n",
    "    WHEN EXTRACT (HOUR FROM TIME(start_date)) IN (7, 8, 9) THEN 'Yes'\n",
    "    WHEN EXTRACT (HOUR FROM TIME(start_date)) IN (16, 17, 18) THEN 'Yes'\n",
    "    ELSE 'No'\n",
    "    END AS commute,\n",
    "  start_station_name,\n",
    "  start_station_id,\n",
    "  end_station_name,\n",
    "  end_station_id,\n",
    "  zip_code,\n",
    "  duration_sec,\n",
    "  subscriber_type,\n",
    "FROM\n",
    "  `bigquery-public-data.san_francisco.bikeshare_trips`;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `bike_trip_data.status_w_availability`\n",
    "\n",
    "```sql\n",
    "SELECT station_id, \n",
    "       DATE(time) AS status_check_date,\n",
    "       TIME(time) AS status_check_time,\n",
    "       CASE EXTRACT (DAYOFWEEK FROM DATE(time))\n",
    "           WHEN 1 THEN 'Sunday'\n",
    "           WHEN 2 THEN 'Monday'\n",
    "           WHEN 3 THEN 'Tuesday'\n",
    "           WHEN 4 THEN 'Wednesday'\n",
    "           WHEN 5 THEN 'Thursday'\n",
    "           WHEN 6 THEN 'Friday'\n",
    "           WHEN 7 THEN 'Saturday'\n",
    "           END AS status_check_day_of_week,\n",
    "       docks_available, bikes_available,\n",
    "       (docks_available + bikes_available) AS total_bikes,\n",
    "       CASE\n",
    "           WHEN bikes_available = 0 AND docks_available = 0 THEN 'NA'\n",
    "           WHEN bikes_available / (docks_available + bikes_available) < 0.25 THEN 'low'\n",
    "           ELSE 'high'\n",
    "           END AS bike_availability,\n",
    "FROM `bigquery-public-data.san_francisco.bikeshare_status`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `bike_trip_data.end_trip_landmarks`\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM `bike_trip_data.trips_full_commute_pst` AS trips\n",
    "INNER JOIN (SELECT station_id, landmark FROM `bigquery-public-data.san_francisco.bikeshare_stations`) AS stations\n",
    "ON trips.end_station_id = stations.station_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `bike_trip_data.trips_seasons_year`\n",
    "\n",
    "```sql\n",
    "SELECT pst_trip_id, start_date_pst, start_time_pst, end_date_pst, end_time_pst, subscriber_type,\n",
    "  EXTRACT(YEAR FROM start_date_pst) AS year,\n",
    "  CASE\n",
    "    WHEN EXTRACT(MONTH FROM start_date_pst) IN (12, 1, 2) THEN 'Winter'\n",
    "    WHEN EXTRACT(MONTH FROM start_date_pst) IN (3, 4, 5) THEN 'Spring'\n",
    "    WHEN EXTRACT(MONTH FROM start_date_pst) IN (6, 7, 8) THEN 'Summer'\n",
    "    WHEN EXTRACT(MONTH FROM start_date_pst) IN (9, 10, 11) THEN 'Fall'\n",
    "    ELSE 'NA'\n",
    "    END AS start_date_month,\n",
    "FROM `bike_trip_data.trips_full_commute_pst`;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
